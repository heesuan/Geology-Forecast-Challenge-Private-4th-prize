{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# ------------------- 🔹 데이터 불러오기 -------------------\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 🔹 geology_id 저장 (나중에 submission에 추가)\n",
        "test_ids = test[\"geology_id\"]\n",
        "\n",
        "# 🔹 train 데이터에서 -299~-1을 입력(X), 1~300을 타겟(y)으로 분리\n",
        "X_train_full = train.iloc[:, 1:301]  # -299 ~ 0\n",
        "y_train_full = train.iloc[:, 301:601]   # 1 ~ 300\n",
        "\n",
        "# 🔹 test에서도 동일한 방식으로 -299~-1을 입력으로 사용\n",
        "X_test_full = test.iloc[:, 1:301]  # -299 ~ -1\n",
        "\n",
        "# ------------------- 🔹 데이터 전처리 함수 -------------------\n",
        "\n",
        "# -299 ~ -k 범위에서 결측치가 시작되는 첫 번째 열 (-k)을 찾는 함수\n",
        "def find_k(series):\n",
        "    notna_index = series.notna()\n",
        "    if notna_index.any():\n",
        "        return int(series.index[notna_index.argmax()])\n",
        "    return None  # 모든 값이 NaN이면 None 반환\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from scipy.interpolate import PchipInterpolator, UnivariateSpline\n",
        "\n",
        "# 🔹 기존 선형 회귀 함수 이름 변경\n",
        "def Linear_prediction(x_known, y_known, x_missing):\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_known.reshape(-1, 1), y_known)\n",
        "    return model.predict(x_missing.reshape(-1, 1))\n",
        "\n",
        "# 🔹 PCHIP 보간 함수\n",
        "def PCHIP_prediction(x_known, y_known, x_missing):\n",
        "    interpolator = PchipInterpolator(x_known, y_known, extrapolate=True)\n",
        "    return interpolator(x_missing)\n",
        "\n",
        "# 🔹 KNN 회귀 기반 보간 함수\n",
        "def KNN_prediction(x_known, y_known, x_missing, k=3):\n",
        "    model = KNeighborsRegressor(n_neighbors=min(k, len(x_known)))\n",
        "    model.fit(x_known.reshape(-1, 1), y_known)\n",
        "    return model.predict(x_missing.reshape(-1, 1))\n",
        "\n",
        "# 🔹 Univariate Spline 보간 함수\n",
        "def Spline_prediction(x_known, y_known, x_missing, s=0):\n",
        "    spline = UnivariateSpline(x_known, y_known, s=s, ext=0)\n",
        "    return spline(x_missing)\n",
        "\n",
        "def evaluate_smoothness(y_full, w1, w2, w3):\n",
        "    dy = np.gradient(y_full)\n",
        "    ddy = np.gradient(dy)\n",
        "\n",
        "    curvature_var = np.var(ddy)\n",
        "    max_curvature = np.max(np.abs(ddy))\n",
        "    num_sharp_turns = np.sum(np.abs(ddy) > 0.01)\n",
        "\n",
        "    return (\n",
        "        curvature_var * w1 +\n",
        "        max_curvature * w2 +\n",
        "        num_sharp_turns * w3\n",
        "    )\n",
        "\n",
        "# 🔹 통합 결측치 예측 함수\n",
        "def predict_missing_values(data,w1=1,w2=0.5,w3=0.3):\n",
        "    filled_data = data.copy()\n",
        "\n",
        "    for i in range(data.shape[0]):\n",
        "        row_data = data.iloc[i, 1:301]  # -299 ~ 0\n",
        "        k_value = find_k(row_data)\n",
        "        if k_value is None:\n",
        "            continue\n",
        "\n",
        "        k_index = row_data.index.get_loc(str(k_value))\n",
        "\n",
        "        for j in range(k_index, -1, -1):  # 결측치 위치 반복 (-k ~ -299)\n",
        "            if pd.notna(row_data.iloc[j]):\n",
        "                continue\n",
        "\n",
        "            x_known = row_data.iloc[j+1:].dropna()\n",
        "            if x_known.empty:\n",
        "                continue\n",
        "\n",
        "            x_known_idx = x_known.index.astype(float).to_numpy()\n",
        "            y_known = x_known.to_numpy()\n",
        "            x_missing_idx = np.array([float(row_data.index[j])])\n",
        "\n",
        "            candidates = {}\n",
        "            try:\n",
        "                y_lin = Linear_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"linear\"] = y_lin\n",
        "            except:\n",
        "                pass\n",
        "            try:\n",
        "                y_pchip = PCHIP_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"pchip\"] = y_pchip\n",
        "            except:\n",
        "                pass\n",
        "            try:\n",
        "                y_spline = Spline_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"spline\"] = y_spline\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # 각 후보에 대해 해당 위치에 값 추가하고 자연스러움 평가\n",
        "            best_method = None\n",
        "            best_score = float(\"inf\")\n",
        "            for method, y_pred in candidates.items():\n",
        "                temp_series = row_data.copy()\n",
        "                temp_series.iloc[j] = y_pred[0]\n",
        "                temp_array = temp_series.dropna().to_numpy()\n",
        "                score = evaluate_smoothness(temp_array,w1,w2,w3)\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_method = method\n",
        "\n",
        "            if best_method:\n",
        "                filled_data.iat[i, j+1] = candidates[best_method][0]\n",
        "                print(f\"Row {i}, Col {row_data.index[j]} -> {best_method}\")\n",
        "\n",
        "    return filled_data\n",
        "\n",
        "# ------------------- 🔹 전처리 과정 결과 저장 -------------------\n",
        "\n",
        "# 🔹 train 데이터 결측치 처리\n",
        "filled_train = predict_missing_values(train)\n",
        "filled_train.to_csv(\"filled_train2.csv\", index=False)\n",
        "print(\"결측치 보완 완료! 'filled_train1.csv' 파일로 저장되었습니다.\")\n",
        "\n",
        "# 🔹 test 데이터 결측치 처리\n",
        "filled_test = predict_missing_values(test)\n",
        "filled_test.to_csv(\"filled_test2.csv\", index=False)\n",
        "print(\"결측치 보완 완료! 'filled_test1.csv' 파일로 저장되었습니다.\")\n",
        "\n",
        "# 🔹 geology_id 컬럼 제거 후 학습 데이터 준비\n",
        "X_train_clean = filled_train.iloc[:, 1:301]  # geology_id 제외\n",
        "X_test_clean = filled_test.iloc[:, 1:301]  # geology_id 제외\n",
        "# ------------------- 🔹 모델 정의 및 학습 -------------------\n",
        "# 🔹 정규화\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_clean)\n",
        "X_test_scaled = scaler.transform(X_test_clean)\n",
        "\n",
        "X_train_seq = X_train_scaled.reshape(-1, 300, 1)\n",
        "X_test_seq = X_test_scaled.reshape(-1, 300, 1)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# EarlyStopping 콜백 정의\n",
        "early_stop = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# 모델 정의 함수 수정: LSTM 유닛 수 증가\n",
        "def build_gru(input_shape=(300, 1)):\n",
        "    model = Sequential([\n",
        "        tf.keras.layers.GRU(256, return_sequences=False, input_shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(300)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# 모델 초기화\n",
        "model_gru = build_gru()\n",
        "\n",
        "# 학습 수행: EarlyStopping\n",
        "\n",
        "model_gru.fit(\n",
        "    X_train_seq, y_train_full.values,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 예측\n",
        "pred_gru = model_gru.predict(X_test_seq)\n",
        "\n",
        "# 앙상블 (단순 평균)\n",
        "y_test_pred = pred_gru\n",
        "\n",
        "# ------------------- 🔹 결과 제출 -------------------\n",
        "\n",
        "columns_new = [str(i+1) for i in range(300)]\n",
        "for r in range(1, 10):\n",
        "    for pos in range(1, 301):\n",
        "        columns_new.append(f\"r_{r}_pos_{pos}\")\n",
        "\n",
        "if y_test_pred.shape[1] < len(columns_new):\n",
        "    y_test_pred = np.pad(y_test_pred, ((0, 0), (0, len(columns_new) - y_test_pred.shape[1])), constant_values=np.nan)\n",
        "\n",
        "submission = pd.DataFrame(y_test_pred, columns=columns_new)\n",
        "submission.insert(0, \"geology_id\", test_ids)\n",
        "\n",
        "copied_part = submission.iloc[:, 1:301].copy().values\n",
        "for start in range(301, 3001, 300):\n",
        "    submission.iloc[:, start:start+300] = copied_part\n",
        "\n",
        "submission.to_csv(\"voting_unit_submission.csv\", index=False)\n",
        "print(\"✅ voting_unit_submission.csv 생성됨\")"
      ],
      "metadata": {
        "id": "WIVN9X8W6KOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}