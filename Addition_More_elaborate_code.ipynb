{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# ------------------- ğŸ”¹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° -------------------\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# ğŸ”¹ geology_id ì €ì¥ (ë‚˜ì¤‘ì— submissionì— ì¶”ê°€)\n",
        "test_ids = test[\"geology_id\"]\n",
        "\n",
        "# ğŸ”¹ train ë°ì´í„°ì—ì„œ -299~-1ì„ ì…ë ¥(X), 1~300ì„ íƒ€ê²Ÿ(y)ìœ¼ë¡œ ë¶„ë¦¬\n",
        "X_train_full = train.iloc[:, 1:301]  # -299 ~ 0\n",
        "y_train_full = train.iloc[:, 301:601]   # 1 ~ 300\n",
        "\n",
        "# ğŸ”¹ testì—ì„œë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ -299~-1ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "X_test_full = test.iloc[:, 1:301]  # -299 ~ -1\n",
        "\n",
        "# ------------------- ğŸ”¹ ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ -------------------\n",
        "\n",
        "# -299 ~ -k ë²”ìœ„ì—ì„œ ê²°ì¸¡ì¹˜ê°€ ì‹œì‘ë˜ëŠ” ì²« ë²ˆì§¸ ì—´ (-k)ì„ ì°¾ëŠ” í•¨ìˆ˜\n",
        "def find_k(series):\n",
        "    notna_index = series.notna()\n",
        "    if notna_index.any():\n",
        "        return int(series.index[notna_index.argmax()])\n",
        "    return None  # ëª¨ë“  ê°’ì´ NaNì´ë©´ None ë°˜í™˜\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from scipy.interpolate import PchipInterpolator, UnivariateSpline\n",
        "\n",
        "# ğŸ”¹ ê¸°ì¡´ ì„ í˜• íšŒê·€ í•¨ìˆ˜ ì´ë¦„ ë³€ê²½\n",
        "def Linear_prediction(x_known, y_known, x_missing):\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_known.reshape(-1, 1), y_known)\n",
        "    return model.predict(x_missing.reshape(-1, 1))\n",
        "\n",
        "# ğŸ”¹ PCHIP ë³´ê°„ í•¨ìˆ˜\n",
        "def PCHIP_prediction(x_known, y_known, x_missing):\n",
        "    interpolator = PchipInterpolator(x_known, y_known, extrapolate=True)\n",
        "    return interpolator(x_missing)\n",
        "\n",
        "# ğŸ”¹ KNN íšŒê·€ ê¸°ë°˜ ë³´ê°„ í•¨ìˆ˜\n",
        "def KNN_prediction(x_known, y_known, x_missing, k=3):\n",
        "    model = KNeighborsRegressor(n_neighbors=min(k, len(x_known)))\n",
        "    model.fit(x_known.reshape(-1, 1), y_known)\n",
        "    return model.predict(x_missing.reshape(-1, 1))\n",
        "\n",
        "# ğŸ”¹ Univariate Spline ë³´ê°„ í•¨ìˆ˜\n",
        "def Spline_prediction(x_known, y_known, x_missing, s=0):\n",
        "    spline = UnivariateSpline(x_known, y_known, s=s, ext=0)\n",
        "    return spline(x_missing)\n",
        "\n",
        "def evaluate_smoothness(y_full, w1, w2, w3):\n",
        "    dy = np.gradient(y_full)\n",
        "    ddy = np.gradient(dy)\n",
        "\n",
        "    curvature_var = np.var(ddy)\n",
        "    max_curvature = np.max(np.abs(ddy))\n",
        "    num_sharp_turns = np.sum(np.abs(ddy) > 0.01)\n",
        "\n",
        "    return (\n",
        "        curvature_var * w1 +\n",
        "        max_curvature * w2 +\n",
        "        num_sharp_turns * w3\n",
        "    )\n",
        "\n",
        "# ğŸ”¹ í†µí•© ê²°ì¸¡ì¹˜ ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "def predict_missing_values(data,w1=1,w2=0.5,w3=0.3):\n",
        "    filled_data = data.copy()\n",
        "\n",
        "    for i in range(data.shape[0]):\n",
        "        row_data = data.iloc[i, 1:301]  # -299 ~ 0\n",
        "        k_value = find_k(row_data)\n",
        "        if k_value is None:\n",
        "            continue\n",
        "\n",
        "        k_index = row_data.index.get_loc(str(k_value))\n",
        "\n",
        "        for j in range(k_index, -1, -1):  # ê²°ì¸¡ì¹˜ ìœ„ì¹˜ ë°˜ë³µ (-k ~ -299)\n",
        "            if pd.notna(row_data.iloc[j]):\n",
        "                continue\n",
        "\n",
        "            x_known = row_data.iloc[j+1:].dropna()\n",
        "            if x_known.empty:\n",
        "                continue\n",
        "\n",
        "            x_known_idx = x_known.index.astype(float).to_numpy()\n",
        "            y_known = x_known.to_numpy()\n",
        "            x_missing_idx = np.array([float(row_data.index[j])])\n",
        "\n",
        "            candidates = {}\n",
        "            try:\n",
        "                y_lin = Linear_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"linear\"] = y_lin\n",
        "            except:\n",
        "                pass\n",
        "            try:\n",
        "                y_pchip = PCHIP_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"pchip\"] = y_pchip\n",
        "            except:\n",
        "                pass\n",
        "            try:\n",
        "                y_spline = Spline_prediction(x_known_idx, y_known, x_missing_idx)\n",
        "                candidates[\"spline\"] = y_spline\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # ê° í›„ë³´ì— ëŒ€í•´ í•´ë‹¹ ìœ„ì¹˜ì— ê°’ ì¶”ê°€í•˜ê³  ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€\n",
        "            best_method = None\n",
        "            best_score = float(\"inf\")\n",
        "            for method, y_pred in candidates.items():\n",
        "                temp_series = row_data.copy()\n",
        "                temp_series.iloc[j] = y_pred[0]\n",
        "                temp_array = temp_series.dropna().to_numpy()\n",
        "                score = evaluate_smoothness(temp_array,w1,w2,w3)\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_method = method\n",
        "\n",
        "            if best_method:\n",
        "                filled_data.iat[i, j+1] = candidates[best_method][0]\n",
        "                print(f\"Row {i}, Col {row_data.index[j]} -> {best_method}\")\n",
        "\n",
        "    return filled_data\n",
        "\n",
        "# ------------------- ğŸ”¹ ì „ì²˜ë¦¬ ê³¼ì • ê²°ê³¼ ì €ì¥ -------------------\n",
        "\n",
        "# ğŸ”¹ train ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
        "filled_train = predict_missing_values(train)\n",
        "filled_train.to_csv(\"filled_train2.csv\", index=False)\n",
        "print(\"ê²°ì¸¡ì¹˜ ë³´ì™„ ì™„ë£Œ! 'filled_train1.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ğŸ”¹ test ë°ì´í„° ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
        "filled_test = predict_missing_values(test)\n",
        "filled_test.to_csv(\"filled_test2.csv\", index=False)\n",
        "print(\"ê²°ì¸¡ì¹˜ ë³´ì™„ ì™„ë£Œ! 'filled_test1.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ğŸ”¹ geology_id ì»¬ëŸ¼ ì œê±° í›„ í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
        "X_train_clean = filled_train.iloc[:, 1:301]  # geology_id ì œì™¸\n",
        "X_test_clean = filled_test.iloc[:, 1:301]  # geology_id ì œì™¸\n",
        "# ------------------- ğŸ”¹ ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ -------------------\n",
        "# ğŸ”¹ ì •ê·œí™”\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_clean)\n",
        "X_test_scaled = scaler.transform(X_test_clean)\n",
        "\n",
        "X_train_seq = X_train_scaled.reshape(-1, 300, 1)\n",
        "X_test_seq = X_test_scaled.reshape(-1, 300, 1)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# EarlyStopping ì½œë°± ì •ì˜\n",
        "early_stop = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ í•¨ìˆ˜ ìˆ˜ì •: LSTM ìœ ë‹› ìˆ˜ ì¦ê°€\n",
        "def build_gru(input_shape=(300, 1)):\n",
        "    model = Sequential([\n",
        "        tf.keras.layers.GRU(256, return_sequences=False, input_shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(300)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model_gru = build_gru()\n",
        "\n",
        "# í•™ìŠµ ìˆ˜í–‰: EarlyStopping\n",
        "\n",
        "model_gru.fit(\n",
        "    X_train_seq, y_train_full.values,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "pred_gru = model_gru.predict(X_test_seq)\n",
        "\n",
        "# ì•™ìƒë¸” (ë‹¨ìˆœ í‰ê· )\n",
        "y_test_pred = pred_gru\n",
        "\n",
        "# ------------------- ğŸ”¹ ê²°ê³¼ ì œì¶œ -------------------\n",
        "\n",
        "columns_new = [str(i+1) for i in range(300)]\n",
        "for r in range(1, 10):\n",
        "    for pos in range(1, 301):\n",
        "        columns_new.append(f\"r_{r}_pos_{pos}\")\n",
        "\n",
        "if y_test_pred.shape[1] < len(columns_new):\n",
        "    y_test_pred = np.pad(y_test_pred, ((0, 0), (0, len(columns_new) - y_test_pred.shape[1])), constant_values=np.nan)\n",
        "\n",
        "submission = pd.DataFrame(y_test_pred, columns=columns_new)\n",
        "submission.insert(0, \"geology_id\", test_ids)\n",
        "\n",
        "copied_part = submission.iloc[:, 1:301].copy().values\n",
        "for start in range(301, 3001, 300):\n",
        "    submission.iloc[:, start:start+300] = copied_part\n",
        "\n",
        "submission.to_csv(\"voting_unit_submission.csv\", index=False)\n",
        "print(\"âœ… voting_unit_submission.csv ìƒì„±ë¨\")"
      ],
      "metadata": {
        "id": "WIVN9X8W6KOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}